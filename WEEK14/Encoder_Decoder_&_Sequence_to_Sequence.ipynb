{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder - Decoder & Sequence to Sequence",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOReToH2mxIYsTMxc24k9bO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NAMA: KOMANG JAYA BHASKARA MAHATYA\n",
        "NIM : 1103181031\n",
        "WEEK 14 - Encoder, Decoder & Sequence to Sequence"
      ],
      "metadata": {
        "id": "qVuUsnbR3MMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "!pip install d2l==0.14.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noP7Hh5aC-Aw",
        "outputId": "b902675e-e5f1-4b8b-c00a-d494071098d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==0.14.2\n",
            "  Downloading d2l-0.14.2-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==0.14.2) (1.21.5)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l==0.14.2) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==0.14.2) (1.2.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==0.14.2) (3.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.14.2) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.14.2) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.14.2) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.14.2) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.14.2) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.14.2) (7.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.14.2) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.14.2) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.14.2) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.14.2) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l==0.14.2) (1.15.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.14.2) (1.1.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.14.2) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.14.2) (3.6.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.14.2) (5.4.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (4.10.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (2.15.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (0.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (4.1.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (4.11.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.14.2) (3.8.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.14.2) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.14.2) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.14.2) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==0.14.2) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==0.14.2) (23.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.14.2) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l==0.14.2) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.14.2) (1.4.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.14.2) (4.33.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.14.2) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.14.2) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.14.2) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.14.2) (3.0.9)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.14.2) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.14.2) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.14.2) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.14.2) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.14.2) (5.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.14.2) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.14.2) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.14.2) (2022.1)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.14.2) (2.1.0)\n",
            "Installing collected packages: d2l\n",
            "  Attempting uninstall: d2l\n",
            "    Found existing installation: d2l 0.17.5\n",
            "    Uninstalling d2l-0.17.5:\n",
            "      Successfully uninstalled d2l-0.17.5\n",
            "Successfully installed d2l-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENCODER**"
      ],
      "metadata": {
        "id": "DhtNkXY3D95n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq6wtBT_BHbD"
      },
      "outputs": [],
      "source": [
        "#@save\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, X, *args, **kwargs):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECODER**"
      ],
      "metadata": {
        "id": "ba9Is0kTEKhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "\n",
        "    def init_state(self, enc_outputs, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def call(self, X, state, **kwargs):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "wDvq1y_hBPvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENCODER - DECODER**"
      ],
      "metadata": {
        "id": "qMGA7CR8ENji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "class EncoderDecoder(tf.keras.Model):\n",
        "    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(EncoderDecoder, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, enc_X, dec_X, *args, **kwargs):\n",
        "        enc_outputs = self.encoder(enc_X, *args, **kwargs)\n",
        "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
        "        return self.decoder(dec_X, dec_state, **kwargs)"
      ],
      "metadata": {
        "id": "qkwSa0tVBTCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "from d2l import tensorflow as d2l"
      ],
      "metadata": {
        "id": "1KNJODtyC5s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEQUENCE TO SEQUENCE - ENCODER**"
      ],
      "metadata": {
        "id": "MuD0on7yERNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "class Seq2SeqEncoder(Encoder):\n",
        "    \"\"\"The RNN encoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
        "        super().__init__(*kwargs)\n",
        "        # Embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells(\n",
        "            [tf.keras.layers.GRUCell(num_hiddens, dropout=dropout)\n",
        "             for _ in range(num_layers)]), return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, X, *args, **kwargs):\n",
        "        # The input `X` shape: (`batch_size`, `num_steps`)\n",
        "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\n",
        "        X = self.embedding(X)\n",
        "        output = self.rnn(X, **kwargs)\n",
        "        state = output[1:]\n",
        "        return output[0], state"
      ],
      "metadata": {
        "id": "wfO18A38DZYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
        "X = tf.zeros((4, 7))\n",
        "output, state = encoder(X, training=False)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwSrtibUDrV1",
        "outputId": "106683df-d4fd-45d0-e845-38255a39f7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 7, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(state), [element.shape for element in state]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NfCXXqUDvMx",
        "outputId": "07ea1b29-feff-4915-b75b-4ab67c9185d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, [TensorShape([4, 16]), TensorShape([4, 16])])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEQUENCE TO SEQUENCE - DECODER**"
      ],
      "metadata": {
        "id": "gg-svqE-D1Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqDecoder(Decoder):\n",
        "    \"\"\"The RNN decoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = tf.keras.layers.RNN(tf.keras.layers.StackedRNNCells(\n",
        "            [tf.keras.layers.GRUCell(num_hiddens, dropout=dropout)\n",
        "             for _ in range(num_layers)]), return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, *args):\n",
        "        return enc_outputs[1]\n",
        "\n",
        "    def call(self, X, state, **kwargs):\n",
        "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\n",
        "        X = self.embedding(X)\n",
        "        # Broadcast `context` so it has the same `num_steps` as `X`\n",
        "        context = tf.repeat(tf.expand_dims(state[-1], axis=1), repeats=X.shape[1], axis=1)\n",
        "        X_and_context = tf.concat((X, context), axis=2)\n",
        "        rnn_output = self.rnn(X_and_context, state, **kwargs)\n",
        "        output = self.dense(rnn_output[0])\n",
        "        # `output` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
        "        # `state` is a list with `num_layers` entries. Each entry has shape:\n",
        "        # (`batch_size`, `num_hiddens`)\n",
        "        return output, rnn_output[1:]"
      ],
      "metadata": {
        "id": "PxZDR5lcDxgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16, num_layers=2)\n",
        "state = decoder.init_state(encoder(X))\n",
        "output, state = decoder(X, state, training=False)\n",
        "output.shape, len(state), state[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Y1Hxq9D0bj",
        "outputId": "ea568e77-2629-453c-a168-3ecdbf689d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([4, 7, 10]), 2, TensorShape([4, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOSS FUNCTION**"
      ],
      "metadata": {
        "id": "VubQ_wRcEZzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "def sequence_mask(X, valid_len, value=0):\n",
        "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
        "    maxlen = X.shape[1]\n",
        "    mask = tf.range(start=0, limit=maxlen, dtype=tf.float32)[\n",
        "        None, :] < tf.cast(valid_len[:, None], dtype=tf.float32)\n",
        "\n",
        "    if len(X.shape) == 3:\n",
        "        return tf.where(tf.expand_dims(mask, axis=-1), X, value)\n",
        "    else:\n",
        "        return tf.where(mask, X, value)\n",
        "\n",
        "X = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "sequence_mask(X, tf.constant([1, 2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LISGzaPvEXUY",
        "outputId": "a3dce84d-6e88-4a81-e90f-7ac007949bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 0, 0],\n",
              "       [4, 5, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.ones((2,3,4))\n",
        "sequence_mask(X, tf.constant([1, 2]), value=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D43K5rjsEdWT",
        "outputId": "cc8ee0c5-c7fd-4722-fb02-1cd7885c8322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
              "array([[[ 1.,  1.,  1.,  1.],\n",
              "        [-1., -1., -1., -1.],\n",
              "        [-1., -1., -1., -1.]],\n",
              "\n",
              "       [[ 1.,  1.,  1.,  1.],\n",
              "        [ 1.,  1.,  1.,  1.],\n",
              "        [-1., -1., -1., -1.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "class MaskedSoftmaxCELoss(tf.keras.losses.Loss):\n",
        "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
        "    def __init__(self, valid_len):\n",
        "        super().__init__(reduction='none')\n",
        "        self.valid_len = valid_len\n",
        "\n",
        "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
        "    # `label` shape: (`batch_size`, `num_steps`)\n",
        "    # `valid_len` shape: (`batch_size`,)\n",
        "    def call(self, label, pred):\n",
        "        weights = tf.ones_like(label, dtype=tf.float32)\n",
        "        weights = sequence_mask(weights, self.valid_len)\n",
        "        label_one_hot = tf.one_hot(label, depth=pred.shape[-1])\n",
        "        unweighted_loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "            from_logits=True, reduction='none')(label_one_hot, pred)\n",
        "        weighted_loss = tf.reduce_mean((unweighted_loss*weights), axis=1)\n",
        "        return weighted_loss"
      ],
      "metadata": {
        "id": "p0QnkRopEfgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = MaskedSoftmaxCELoss(tf.constant([4, 2, 0]))\n",
        "loss(tf.ones((3,4), dtype = tf.int32), tf.ones((3, 4, 10))).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpOog--YEhGd",
        "outputId": "a1c2e8e8-c566-4e58-9cb1-3abb626f3d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.3025851, 1.1512926, 0.       ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING**"
      ],
      "metadata": {
        "id": "m-86SAT0EkI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
        "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    animator = d2l.Animator(xlabel=\"epoch\", ylabel=\"loss\",\n",
        "                            xlim=[10, num_epochs])\n",
        "    for epoch in range(num_epochs):\n",
        "        timer = d2l.Timer()\n",
        "        metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n",
        "        for batch in data_iter:\n",
        "            X, X_valid_len, Y, Y_valid_len = [x for x in batch]\n",
        "            bos = tf.reshape(tf.constant([tgt_vocab['<bos>']] * Y.shape[0]),\n",
        "                             shape=(-1, 1))\n",
        "            dec_input = tf.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
        "            with tf.GradientTape() as tape:\n",
        "                Y_hat, _ = net(X, dec_input, X_valid_len, training=True)\n",
        "                l = MaskedSoftmaxCELoss(Y_valid_len)(Y, Y_hat)\n",
        "            gradients = tape.gradient(l, net.trainable_variables)\n",
        "            gradients = d2l.grad_clipping(gradients, 1)\n",
        "            optimizer.apply_gradients(zip(gradients, net.trainable_variables))\n",
        "            num_tokens = tf.reduce_sum(Y_valid_len).numpy()\n",
        "            metric.add(tf.reduce_sum(l), num_tokens)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
        "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
        "          f'tokens/sec on {str(device)}')"
      ],
      "metadata": {
        "id": "J03A_2EkEioH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}